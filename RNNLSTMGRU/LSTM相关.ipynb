{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long Short Term Mermory network（LSTM）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Long Short Term Mermory network（LSTM）是一种特殊的RNNs，可以很好地解决长时依赖问题。\n",
    "\n",
    "理解LSTMs的关键就是memory block（记忆块），主要包含了三个门（forget gate、input gate、output gate）与一个记忆单元（cell）。方框内上方的那条水平线，被称为cell state（单元状态），它就像一个传送带，可以控制信息传递给下一时刻。\n",
    "\n",
    "$f_t=\\sigma (w_f \\cdot [h_{t-1} ,x_t] +b_f  ) $\n",
    "\n",
    "$i_t=\\sigma (w_i \\cdot [h_{t-1} ,x_t] +b_i) $\n",
    "\n",
    "$\\widetilde{C_t}=tanh( w_c \\cdot [h_{t-1} ,x_t] +b_c) $\n",
    "\n",
    "$ C_t=f_t * C_{t-1} + i_t * \\widetilde{C_t} $\n",
    "\n",
    "$o_t=\\sigma (w_o \\cdot [h_{t-1} ,x_t] +b_o) $\n",
    "\n",
    "$h_t= o_t * tanh(C_t)$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.api._v2.keras' has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32me:\\坚果云\\精益求精\\warmup\\RNNLSTMGRU\\LSTM相关.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%E5%9D%9A%E6%9E%9C%E4%BA%91/%E7%B2%BE%E7%9B%8A%E6%B1%82%E7%B2%BE/warmup/RNNLSTMGRU/LSTM%E7%9B%B8%E5%85%B3.ipynb#ch0000004?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtensorflow\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mtf\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/%E5%9D%9A%E6%9E%9C%E4%BA%91/%E7%B2%BE%E7%9B%8A%E6%B1%82%E7%B2%BE/warmup/RNNLSTMGRU/LSTM%E7%9B%B8%E5%85%B3.ipynb#ch0000004?line=2'>3</a>\u001b[0m model \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39;49mkeras\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39mSequential(\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%E5%9D%9A%E6%9E%9C%E4%BA%91/%E7%B2%BE%E7%9B%8A%E6%B1%82%E7%B2%BE/warmup/RNNLSTMGRU/LSTM%E7%9B%B8%E5%85%B3.ipynb#ch0000004?line=3'>4</a>\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mEmbedding(\u001b[39m1000\u001b[39m, \u001b[39m128\u001b[39m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%E5%9D%9A%E6%9E%9C%E4%BA%91/%E7%B2%BE%E7%9B%8A%E6%B1%82%E7%B2%BE/warmup/RNNLSTMGRU/LSTM%E7%9B%B8%E5%85%B3.ipynb#ch0000004?line=4'>5</a>\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mLSTM(units\u001b[39m=\u001b[39m\u001b[39m64\u001b[39m),\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%E5%9D%9A%E6%9E%9C%E4%BA%91/%E7%B2%BE%E7%9B%8A%E6%B1%82%E7%B2%BE/warmup/RNNLSTMGRU/LSTM%E7%9B%B8%E5%85%B3.ipynb#ch0000004?line=5'>6</a>\u001b[0m     tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m10\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%E5%9D%9A%E6%9E%9C%E4%BA%91/%E7%B2%BE%E7%9B%8A%E6%B1%82%E7%B2%BE/warmup/RNNLSTMGRU/LSTM%E7%9B%B8%E5%85%B3.ipynb#ch0000004?line=6'>7</a>\u001b[0m )\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%E5%9D%9A%E6%9E%9C%E4%BA%91/%E7%B2%BE%E7%9B%8A%E6%B1%82%E7%B2%BE/warmup/RNNLSTMGRU/LSTM%E7%9B%B8%E5%85%B3.ipynb#ch0000004?line=7'>8</a>\u001b[0m model\u001b[39m.\u001b[39msummary()\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.api._v2.keras' has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.model.Sequential(\n",
    "    tf.keras.layers.Embedding(1000, 128),\n",
    "    tf.keras.layers.LSTM(units=64),\n",
    "    tf.keras.layers.Dense(10)\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 支持多行输出\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all' #默认为'last'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 导入常用的包\n",
    "import numpy as np\n",
    "from torch import nn,optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data2/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "9913344it [00:03, 2495600.00it/s]                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data2/MNIST\\raw\\train-images-idx3-ubyte.gz to ./data2/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data2/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "29696it [00:00, 4253749.93it/s]          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data2/MNIST\\raw\\train-labels-idx1-ubyte.gz to ./data2/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data2/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1649664it [00:01, 924636.32it/s]                              \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data2/MNIST\\raw\\t10k-images-idx3-ubyte.gz to ./data2/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data2/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5120it [00:00, ?it/s]                   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data2/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to ./data2/MNIST\\raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "d:\\anaconda\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "# 载入数据\n",
    "train_dataset = datasets.MNIST(root = './data2/', # 载入的数据存放的位置\n",
    "                               train = True, # 载入训练集数据\n",
    "                               transform = transforms.ToTensor(), # 将载入进来的数据变成Tensor\n",
    "                               download = True) # 是否下载数据\n",
    "test_dataset = datasets.MNIST(root = './data2/', # 载入的数据存放的位置\n",
    "                               train = False, # 载入测试集数据\n",
    "                               transform = transforms.ToTensor(), # 将载入进来的数据变成Tensor\n",
    "                               download = True) # 是否下载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 批次大小\n",
    "batch_size = 64\n",
    "\n",
    "# 装载训练集\n",
    "train_loader = DataLoader(dataset=train_dataset,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True)\n",
    "\n",
    "# 装载训练集\n",
    "test_loader = DataLoader(dataset=test_dataset,\n",
    "                         batch_size=batch_size,\n",
    "                         shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义网络结构\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LSTM, self).__init__()\n",
    "        # 定义LSTM层(相当于隐藏层)\n",
    "        # input_size 表示数据输入特征的大小\n",
    "        # hidden_size 表示LSTM模块的数量\n",
    "        # num_layers 表示隐藏层的层数, 一般设置1-3层就可以了\n",
    "        # batch_first 用于设置数据格式，默认：input(seq_len, batch, feature)\n",
    "        # 当batch_first = True，则input和output数据的格式变为：(batch, seq_len, feature)\n",
    "        self.lstm = torch.nn.LSTM(\n",
    "            input_size = 28,\n",
    "            hidden_size = 64,\n",
    "            num_layers = 1,\n",
    "            batch_first = True\n",
    "        )\n",
    "        # 定义全连接层\n",
    "        # 这里的in_features=64，是因为LSTM层中hidden_size = 64，每一个LSTM块都会输出一个值.\n",
    "        self.out = torch.nn.Linear(in_features=64, out_features=10)\n",
    "        # softmax\n",
    "        self.softmax = torch.nn.Softmax(dim = 1)\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 我们要将数据reshape成3维数据(batch, seq_len, feature)\n",
    "        # seq_len表示序列长度\n",
    "        # feature：表示每次传入数据的个数\n",
    "        x = x.view(-1, 28, 28)\n",
    "        # output: 包含每个批次的每个序列的每个LSTM单元的输出结果,是3维[batch, seq_len, hidden_size]\n",
    "        # 虽然LSTM的batch_first = True，但是h_n和c_n的第一个维度还是seq_len\n",
    "        # h_n: [num_layers, batch, hidden_size] 只包含最后一个序列的输出结果\n",
    "        # c_n: [num_layers, batch, hidden_size] 只包含最后一个序列的输出结果\n",
    "        output, (h_n, c_n) = self.lstm(x)\n",
    "        # 如果这里有很多隐藏层，那么我们只需要最后一层的输出结果\n",
    "        output_in_last_timestep = h_n[-1, :, :]\n",
    "        x = self.out(output_in_last_timestep)\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 0.0003\n",
    "# 定义模型\n",
    "model = LSTM()\n",
    "# 定义代价函数为交叉熵代价函数\n",
    "mse_loss = nn.CrossEntropyLoss()\n",
    "# 定义优化器Adam\n",
    "optimizer = optim.Adam(model.parameters(), LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    model.train()\n",
    "    for i,data in enumerate(train_loader):\n",
    "        # 获得一个批次的数据和标签\n",
    "        inputs, labels = data\n",
    "        # 获得模型预测结果（64,10）\n",
    "        out = model(inputs)\n",
    "        # 计算loss,交叉熵代价函数out(batch,C), labels(batch)\n",
    "        loss = mse_loss(out, labels)\n",
    "        # 梯度清0\n",
    "        optimizer.zero_grad()\n",
    "        # 计算梯度\n",
    "        loss.backward()\n",
    "        # 修改权值\n",
    "        optimizer.step()\n",
    "\n",
    "def test():\n",
    "    model.eval()\n",
    "    \n",
    "    # 计算训练集准确率\n",
    "    correct = 0\n",
    "    for i,data in enumerate(train_loader):\n",
    "        # 获得一个批次的数据和标签\n",
    "        inputs, labels = data\n",
    "        # 获得模型预测结果（64,10）\n",
    "        out = model(inputs)\n",
    "        # 获得最大值，以及最大值所在的位置\n",
    "        _, predicted = torch.max(out, 1)\n",
    "        # 预测正确的数量\n",
    "        correct += (predicted == labels).sum()\n",
    "    print(\"Train acc:{0}\".format(correct.item()/len(train_dataset)))\n",
    "    \n",
    "    # 计算测试集准确率\n",
    "    correct = 0\n",
    "    for i,data in enumerate(test_loader):\n",
    "        # 获得一个批次的数据和标签\n",
    "        inputs, labels = data\n",
    "        # 获得模型预测结果（64,10）\n",
    "        out = model(inputs)\n",
    "        # 获得最大值，以及最大值所在的位置\n",
    "        _, predicted = torch.max(out, 1)\n",
    "        # 预测正确的数量\n",
    "        correct += (predicted == labels).sum()\n",
    "    print(\"Test acc:{0}\".format(correct.item()/len(test_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0\n",
      "Train acc:0.78\n",
      "Test acc:0.7796\n",
      "epoch: 1\n",
      "Train acc:0.83265\n",
      "Test acc:0.8359\n",
      "epoch: 2\n",
      "Train acc:0.84785\n",
      "Test acc:0.8491\n",
      "epoch: 3\n",
      "Train acc:0.9138\n",
      "Test acc:0.917\n",
      "epoch: 4\n",
      "Train acc:0.9365\n",
      "Test acc:0.9355\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(5):\n",
    "    print('epoch:',epoch)\n",
    "    train()\n",
    "    test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![图片](E:\\坚果云\\精益求精\\warmup\\RNNLSTMGRU\\lstm.PNG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./my_model.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_new = LSTM()\n",
    "# 载入模型\n",
    "model_new.load_state_dict(torch.load(\"./my_model.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame\n",
    "from pandas import Series\n",
    "from pandas import concat\n",
    "from pandas import read_csv\n",
    "from pandas import datetime\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot\n",
    "from numpy import array\n",
    " \n",
    " \n",
    "# 加载数据集\n",
    "def parser(x):\n",
    "    return datetime.strptime(x, '%Y/%m/%d')\n",
    " \n",
    " \n",
    "# 将时间序列转换为监督类型的数据序列\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # 这个for循环是用来输入列标题的 var1(t-1)，var1(t)，var1(t+1)，var1(t+2)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "    # 转换为监督型数据的预测序列 每四个一组，对应 var1(t-1)，var1(t)，var1(t+1)，var1(t+2)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j + 1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j + 1, i)) for j in range(n_vars)]\n",
    "    # 拼接数据\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # 把null值转换为0\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    print(agg)\n",
    "    return agg\n",
    " \n",
    " \n",
    "# 对传入的数列做差分操作，相邻两值相减\n",
    "def difference(dataset, interval=1):\n",
    "    diff = list()\n",
    "    for i in range(interval, len(dataset)):\n",
    "        value = dataset[i] - dataset[i - interval]\n",
    "        diff.append(value)\n",
    "    return Series(diff)\n",
    " \n",
    " \n",
    "# 将序列转换为用于监督学习的训练和测试集\n",
    "def prepare_data(series, n_test, n_lag, n_seq):\n",
    "    # 提取原始值\n",
    "    raw_values = series.values\n",
    "    # 将数据转换为静态的\n",
    "    diff_series = difference(raw_values, 1)\n",
    "    diff_values = diff_series.values\n",
    "    diff_values = diff_values.reshape(len(diff_values), 1)\n",
    "    # 重新调整数据为（-1,1）之间\n",
    "    scaler = MinMaxScaler(feature_range=(-1, 1))\n",
    "    scaled_values = scaler.fit_transform(diff_values)\n",
    "    scaled_values = scaled_values.reshape(len(scaled_values), 1)\n",
    "    # 转化为有监督的数据X，y\n",
    "    supervised = series_to_supervised(scaled_values, n_lag, n_seq)\n",
    "    supervised_values = supervised.values\n",
    "    # 分割为测试数据和训练数据\n",
    "    train, test = supervised_values[0:-n_test], supervised_values[-n_test:]\n",
    "    return scaler, train, test\n",
    " \n",
    " \n",
    "# 匹配LSTM网络训练数据\n",
    "def fit_lstm(train, n_lag, n_seq, n_batch, nb_epoch, n_neurons):\n",
    "    # 重塑训练数据格式 [samples, timesteps, features]\n",
    "    X, y = train[:, 0:n_lag], train[:, n_lag:]\n",
    "    X = X.reshape(X.shape[0], 1, X.shape[1])\n",
    "    # 配置一个LSTM神经网络，添加网络参数\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(n_neurons, batch_input_shape=(n_batch, X.shape[1], X.shape[2]), stateful=True))\n",
    "    model.add(Dense(y.shape[1]))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    # 调用网络，迭代数据对神经网络进行训练，最后输出训练好的网络模型\n",
    "    for i in range(nb_epoch):\n",
    "        model.fit(X, y, epochs=1, batch_size=n_batch, verbose=0, shuffle=False)\n",
    "        model.reset_states()\n",
    "    return model\n",
    " \n",
    " \n",
    "# 用LSTM做预测\n",
    "def forecast_lstm(model, X, n_batch):\n",
    "    # 重构输入参数 [samples, timesteps, features]\n",
    "    X = X.reshape(1, 1, len(X))\n",
    "    # 开始预测\n",
    "    forecast = model.predict(X, batch_size=n_batch)\n",
    "    # 结果转换成数组\n",
    "    return [x for x in forecast[0, :]]\n",
    " \n",
    " \n",
    "# 利用训练好的网络模型，对测试数据进行预测\n",
    "def make_forecasts(model, n_batch, train, test, n_lag, n_seq):\n",
    "    forecasts = list()\n",
    "    # 预测方式是用一个X值预测出后三步的Y值\n",
    "    for i in range(len(test)):\n",
    "        X, y = test[i, 0:n_lag], test[i, n_lag:]\n",
    "        # 调用训练好的模型预测未来数据\n",
    "        forecast = forecast_lstm(model, X, n_batch)\n",
    "        # 将预测的数据保存\n",
    "        forecasts.append(forecast)\n",
    "    return forecasts\n",
    " \n",
    " \n",
    "# 对预测后的缩放值（-1，1）进行逆变换\n",
    "def inverse_difference(last_ob, forecast):\n",
    "    # invert first forecast\n",
    "    inverted = list()\n",
    "    inverted.append(forecast[0] + last_ob)\n",
    "    # propagate difference forecast using inverted first value\n",
    "    for i in range(1, len(forecast)):\n",
    "        inverted.append(forecast[i] + inverted[i - 1])\n",
    "    return inverted\n",
    " \n",
    " \n",
    "# 对预测完成的数据进行逆变换\n",
    "def inverse_transform(series, forecasts, scaler, n_test):\n",
    "    inverted = list()\n",
    "    for i in range(len(forecasts)):\n",
    "        # create array from forecast\n",
    "        forecast = array(forecasts[i])\n",
    "        forecast = forecast.reshape(1, len(forecast))\n",
    "        # 将预测后的数据缩放逆转换\n",
    "        inv_scale = scaler.inverse_transform(forecast)\n",
    "        inv_scale = inv_scale[0, :]\n",
    "        # invert differencing\n",
    "        index = len(series) - n_test + i - 1\n",
    "        last_ob = series.values[index]\n",
    "        # 将预测后的数据差值逆转换\n",
    "        inv_diff = inverse_difference(last_ob, inv_scale)\n",
    "        # 保存数据\n",
    "        inverted.append(inv_diff)\n",
    "    return inverted\n",
    " \n",
    " \n",
    "# 评估每个预测时间步的RMSE\n",
    "def evaluate_forecasts(test, forecasts, n_lag, n_seq):\n",
    "    for i in range(n_seq):\n",
    "        actual = [row[i] for row in test]\n",
    "        predicted = [forecast[i] for forecast in forecasts]\n",
    "        rmse = sqrt(mean_squared_error(actual, predicted))\n",
    "        print('t+%d RMSE: %f' % ((i + 1), rmse))\n",
    " \n",
    " \n",
    "# 在原始数据集的上下文中绘制预测图\n",
    "def plot_forecasts(series, forecasts, n_test):\n",
    "    # plot the entire dataset in blue\n",
    "    pyplot.plot(series.values)\n",
    "    # plot the forecasts in red\n",
    "    for i in range(len(forecasts)):\n",
    "        off_s = len(series) - n_test + i - 1\n",
    "        off_e = off_s + len(forecasts[i]) + 1\n",
    "        xaxis = [x for x in range(off_s, off_e)]\n",
    "        yaxis = [series.values[off_s]] + forecasts[i]\n",
    "        pyplot.plot(xaxis, yaxis, color='red')\n",
    "    # show the plot\n",
    "    pyplot.show()\n",
    " \n",
    " \n",
    "# 加载数据\n",
    "series = read_csv('./shampoo-sales.csv', header=0, parse_dates=[0], index_col=0, squeeze=True, date_parser=parser)\n",
    "# 配置网络信息\n",
    "n_lag = 1\n",
    "n_seq = 3\n",
    "n_test = 10\n",
    "n_epochs = 1500\n",
    "n_batch = 1\n",
    "n_neurons = 1\n",
    "# 准备数据\n",
    "scaler, train, test = prepare_data(series, n_test, n_lag, n_seq)\n",
    "# 准备预测模型\n",
    "model = fit_lstm(train, n_lag, n_seq, n_batch, n_epochs, n_neurons)\n",
    "# 开始预测\n",
    "forecasts = make_forecasts(model, n_batch, train, test, n_lag, n_seq)\n",
    "# 逆转换训练数据和预测数据\n",
    "forecasts = inverse_transform(series, forecasts, scaler, n_test + 2)\n",
    "# 逆转换测试数据\n",
    "actual = [row[n_lag:] for row in test]\n",
    "actual = inverse_transform(series, actual, scaler, n_test + 2)\n",
    "# 比较预测数据和测试数据，计算两者之间的损失值\n",
    "evaluate_forecasts(actual, forecasts, n_lag, n_seq)\n",
    "# 画图\n",
    "plot_forecasts(series, forecasts, n_test + 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     pollution  dew  temp   press wnd_dir  wnd_spd  snow  rain\n",
      "date                                                                          \n",
      "2010-01-02 00:00:00      129.0  -16  -4.0  1020.0      SE     1.79     0     0\n",
      "2010-01-02 01:00:00      148.0  -15  -4.0  1020.0      SE     2.68     0     0\n",
      "2010-01-02 02:00:00      159.0  -11  -5.0  1021.0      SE     3.57     0     0\n",
      "2010-01-02 03:00:00      181.0   -7  -5.0  1022.0      SE     5.36     1     0\n",
      "2010-01-02 04:00:00      138.0   -7  -5.0  1022.0      SE     6.25     2     0\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from datetime import datetime\n",
    "# load data\n",
    "def parse(x):\n",
    "    return datetime.strptime(x, '%Y %m %d %H')\n",
    "dataset = read_csv('./raw.csv',  parse_dates = [['year', 'month', 'day', 'hour']], index_col=0, date_parser=parse)\n",
    "dataset.drop('No', axis=1, inplace=True)\n",
    "# manually specify column names\n",
    "dataset.columns = ['pollution', 'dew', 'temp', 'press', 'wnd_dir', 'wnd_spd', 'snow', 'rain']\n",
    "dataset.index.name = 'date'\n",
    "# mark all NA values with 0\n",
    "dataset['pollution'].fillna(0, inplace=True)\n",
    "# drop the first 24 hours\n",
    "dataset = dataset[24:]\n",
    "# summarize first 5 rows\n",
    "print(dataset.head(5))\n",
    "# save to file\n",
    "dataset.to_csv('pollution.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "# load dataset\n",
    "dataset = read_csv('pollution.csv', header=0, index_col=0)\n",
    "values = dataset.values\n",
    "# specify columns to plot\n",
    "groups = [0, 1, 2, 3, 5, 6, 7]\n",
    "i = 1\n",
    "# plot each column\n",
    "pyplot.figure()\n",
    "for group in groups:\n",
    "    pyplot.subplot(len(groups), 1, i)\n",
    "    pyplot.plot(values[:, group])\n",
    "    pyplot.title(dataset.columns[group], y=0.5, loc='right')\n",
    "    i += 1\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "from matplotlib import pyplot\n",
    "# load dataset\n",
    "dataset = read_csv('pollution.csv', header=0, index_col=0)\n",
    "values = dataset.values\n",
    "# specify columns to plot\n",
    "groups = [0, 1, 2, 3, 5, 6, 7]\n",
    "i = 1\n",
    "# plot each column\n",
    "pyplot.figure()\n",
    "for group in groups:\n",
    "    pyplot.subplot(len(groups), 1, i)\n",
    "    pyplot.plot(values[:, group])\n",
    "    pyplot.title(dataset.columns[group], y=0.5, loc='right')\n",
    "    i += 1\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reframed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\坚果云\\精益求精\\warmup\\RNNLSTMGRU\\LSTM相关.ipynb Cell 19\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%E5%9D%9A%E6%9E%9C%E4%BA%91/%E7%B2%BE%E7%9B%8A%E6%B1%82%E7%B2%BE/warmup/RNNLSTMGRU/LSTM%E7%9B%B8%E5%85%B3.ipynb#ch0000022?line=0'>1</a>\u001b[0m \u001b[39m# split into train and test sets\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/%E5%9D%9A%E6%9E%9C%E4%BA%91/%E7%B2%BE%E7%9B%8A%E6%B1%82%E7%B2%BE/warmup/RNNLSTMGRU/LSTM%E7%9B%B8%E5%85%B3.ipynb#ch0000022?line=1'>2</a>\u001b[0m values \u001b[39m=\u001b[39m reframed\u001b[39m.\u001b[39mvalues\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%E5%9D%9A%E6%9E%9C%E4%BA%91/%E7%B2%BE%E7%9B%8A%E6%B1%82%E7%B2%BE/warmup/RNNLSTMGRU/LSTM%E7%9B%B8%E5%85%B3.ipynb#ch0000022?line=2'>3</a>\u001b[0m n_train_hours \u001b[39m=\u001b[39m \u001b[39m365\u001b[39m \u001b[39m*\u001b[39m \u001b[39m24\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%E5%9D%9A%E6%9E%9C%E4%BA%91/%E7%B2%BE%E7%9B%8A%E6%B1%82%E7%B2%BE/warmup/RNNLSTMGRU/LSTM%E7%9B%B8%E5%85%B3.ipynb#ch0000022?line=3'>4</a>\u001b[0m train \u001b[39m=\u001b[39m values[:n_train_hours, :]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'reframed' is not defined"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_hours = 365 * 24\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reframed' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\坚果云\\精益求精\\warmup\\RNNLSTMGRU\\LSTM相关.ipynb Cell 20\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%E5%9D%9A%E6%9E%9C%E4%BA%91/%E7%B2%BE%E7%9B%8A%E6%B1%82%E7%B2%BE/warmup/RNNLSTMGRU/LSTM%E7%9B%B8%E5%85%B3.ipynb#ch0000023?line=0'>1</a>\u001b[0m \u001b[39m# split into train and test sets\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/%E5%9D%9A%E6%9E%9C%E4%BA%91/%E7%B2%BE%E7%9B%8A%E6%B1%82%E7%B2%BE/warmup/RNNLSTMGRU/LSTM%E7%9B%B8%E5%85%B3.ipynb#ch0000023?line=1'>2</a>\u001b[0m values \u001b[39m=\u001b[39m reframed\u001b[39m.\u001b[39mvalues\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%E5%9D%9A%E6%9E%9C%E4%BA%91/%E7%B2%BE%E7%9B%8A%E6%B1%82%E7%B2%BE/warmup/RNNLSTMGRU/LSTM%E7%9B%B8%E5%85%B3.ipynb#ch0000023?line=2'>3</a>\u001b[0m n_train_hours \u001b[39m=\u001b[39m \u001b[39m365\u001b[39m \u001b[39m*\u001b[39m \u001b[39m24\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%E5%9D%9A%E6%9E%9C%E4%BA%91/%E7%B2%BE%E7%9B%8A%E6%B1%82%E7%B2%BE/warmup/RNNLSTMGRU/LSTM%E7%9B%B8%E5%85%B3.ipynb#ch0000023?line=3'>4</a>\u001b[0m train \u001b[39m=\u001b[39m values[:n_train_hours, :]\n",
      "\u001b[1;31mNameError\u001b[0m: name 'reframed' is not defined"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_hours = 365 * 24\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Sequential' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\坚果云\\精益求精\\warmup\\RNNLSTMGRU\\LSTM相关.ipynb Cell 21\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%E5%9D%9A%E6%9E%9C%E4%BA%91/%E7%B2%BE%E7%9B%8A%E6%B1%82%E7%B2%BE/warmup/RNNLSTMGRU/LSTM%E7%9B%B8%E5%85%B3.ipynb#ch0000024?line=0'>1</a>\u001b[0m \u001b[39m# design network\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/%E5%9D%9A%E6%9E%9C%E4%BA%91/%E7%B2%BE%E7%9B%8A%E6%B1%82%E7%B2%BE/warmup/RNNLSTMGRU/LSTM%E7%9B%B8%E5%85%B3.ipynb#ch0000024?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m Sequential()\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%E5%9D%9A%E6%9E%9C%E4%BA%91/%E7%B2%BE%E7%9B%8A%E6%B1%82%E7%B2%BE/warmup/RNNLSTMGRU/LSTM%E7%9B%B8%E5%85%B3.ipynb#ch0000024?line=2'>3</a>\u001b[0m model\u001b[39m.\u001b[39madd(LSTM(\u001b[39m50\u001b[39m, input_shape\u001b[39m=\u001b[39m(train_X\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m], train_X\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m])))\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%E5%9D%9A%E6%9E%9C%E4%BA%91/%E7%B2%BE%E7%9B%8A%E6%B1%82%E7%B2%BE/warmup/RNNLSTMGRU/LSTM%E7%9B%B8%E5%85%B3.ipynb#ch0000024?line=3'>4</a>\u001b[0m model\u001b[39m.\u001b[39madd(Dense(\u001b[39m1\u001b[39m))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Sequential' is not defined"
     ]
    }
   ],
   "source": [
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    " \n",
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32me:\\坚果云\\精益求精\\warmup\\RNNLSTMGRU\\LSTM相关.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%E5%9D%9A%E6%9E%9C%E4%BA%91/%E7%B2%BE%E7%9B%8A%E6%B1%82%E7%B2%BE/warmup/RNNLSTMGRU/LSTM%E7%9B%B8%E5%85%B3.ipynb#ch0000025?line=0'>1</a>\u001b[0m \u001b[39m# make a prediction\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/e%3A/%E5%9D%9A%E6%9E%9C%E4%BA%91/%E7%B2%BE%E7%9B%8A%E6%B1%82%E7%B2%BE/warmup/RNNLSTMGRU/LSTM%E7%9B%B8%E5%85%B3.ipynb#ch0000025?line=1'>2</a>\u001b[0m yhat \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mpredict(test_X)\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%E5%9D%9A%E6%9E%9C%E4%BA%91/%E7%B2%BE%E7%9B%8A%E6%B1%82%E7%B2%BE/warmup/RNNLSTMGRU/LSTM%E7%9B%B8%E5%85%B3.ipynb#ch0000025?line=2'>3</a>\u001b[0m test_X \u001b[39m=\u001b[39m test_X\u001b[39m.\u001b[39mreshape((test_X\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m], test_X\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m]))\n\u001b[0;32m      <a href='vscode-notebook-cell:/e%3A/%E5%9D%9A%E6%9E%9C%E4%BA%91/%E7%B2%BE%E7%9B%8A%E6%B1%82%E7%B2%BE/warmup/RNNLSTMGRU/LSTM%E7%9B%B8%E5%85%B3.ipynb#ch0000025?line=3'>4</a>\u001b[0m \u001b[39m# invert scaling for forecast\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)  var6(t-1)  \\\n",
      "1   0.129779   0.352941   0.245902   0.527273   0.666667   0.002290   \n",
      "2   0.148893   0.367647   0.245902   0.527273   0.666667   0.003811   \n",
      "3   0.159960   0.426471   0.229508   0.545454   0.666667   0.005332   \n",
      "4   0.182093   0.485294   0.229508   0.563637   0.666667   0.008391   \n",
      "5   0.138833   0.485294   0.229508   0.563637   0.666667   0.009912   \n",
      "\n",
      "   var7(t-1)  var8(t-1)   var1(t)  \n",
      "1   0.000000        0.0  0.148893  \n",
      "2   0.000000        0.0  0.159960  \n",
      "3   0.000000        0.0  0.182093  \n",
      "4   0.037037        0.0  0.138833  \n",
      "5   0.074074        0.0  0.109658  \n",
      "(8760, 1, 8) (8760,) (35039, 1, 8) (35039,)\n",
      "Epoch 1/50\n",
      "122/122 - 9s - loss: 0.0588 - val_loss: 0.0507 - 9s/epoch - 75ms/step\n",
      "Epoch 2/50\n",
      "122/122 - 2s - loss: 0.0395 - val_loss: 0.0463 - 2s/epoch - 14ms/step\n",
      "Epoch 3/50\n",
      "122/122 - 2s - loss: 0.0207 - val_loss: 0.0368 - 2s/epoch - 14ms/step\n",
      "Epoch 4/50\n",
      "122/122 - 2s - loss: 0.0161 - val_loss: 0.0248 - 2s/epoch - 13ms/step\n",
      "Epoch 5/50\n",
      "122/122 - 2s - loss: 0.0151 - val_loss: 0.0174 - 2s/epoch - 13ms/step\n",
      "Epoch 6/50\n",
      "122/122 - 2s - loss: 0.0150 - val_loss: 0.0159 - 2s/epoch - 13ms/step\n",
      "Epoch 7/50\n",
      "122/122 - 2s - loss: 0.0150 - val_loss: 0.0155 - 2s/epoch - 13ms/step\n",
      "Epoch 8/50\n",
      "122/122 - 2s - loss: 0.0149 - val_loss: 0.0151 - 2s/epoch - 13ms/step\n",
      "Epoch 9/50\n",
      "122/122 - 2s - loss: 0.0149 - val_loss: 0.0147 - 2s/epoch - 14ms/step\n",
      "Epoch 10/50\n",
      "122/122 - 2s - loss: 0.0148 - val_loss: 0.0144 - 2s/epoch - 13ms/step\n",
      "Epoch 11/50\n",
      "122/122 - 2s - loss: 0.0146 - val_loss: 0.0140 - 2s/epoch - 14ms/step\n",
      "Epoch 12/50\n",
      "122/122 - 2s - loss: 0.0146 - val_loss: 0.0140 - 2s/epoch - 13ms/step\n",
      "Epoch 13/50\n",
      "122/122 - 2s - loss: 0.0147 - val_loss: 0.0140 - 2s/epoch - 14ms/step\n",
      "Epoch 14/50\n",
      "122/122 - 2s - loss: 0.0146 - val_loss: 0.0139 - 2s/epoch - 13ms/step\n",
      "Epoch 15/50\n",
      "122/122 - 2s - loss: 0.0146 - val_loss: 0.0138 - 2s/epoch - 14ms/step\n",
      "Epoch 16/50\n",
      "122/122 - 2s - loss: 0.0146 - val_loss: 0.0137 - 2s/epoch - 13ms/step\n",
      "Epoch 17/50\n",
      "122/122 - 2s - loss: 0.0145 - val_loss: 0.0136 - 2s/epoch - 14ms/step\n",
      "Epoch 18/50\n",
      "122/122 - 2s - loss: 0.0145 - val_loss: 0.0135 - 2s/epoch - 13ms/step\n",
      "Epoch 19/50\n",
      "122/122 - 2s - loss: 0.0145 - val_loss: 0.0135 - 2s/epoch - 13ms/step\n",
      "Epoch 20/50\n",
      "122/122 - 2s - loss: 0.0145 - val_loss: 0.0134 - 2s/epoch - 14ms/step\n",
      "Epoch 21/50\n",
      "122/122 - 2s - loss: 0.0145 - val_loss: 0.0134 - 2s/epoch - 13ms/step\n",
      "Epoch 22/50\n",
      "122/122 - 2s - loss: 0.0145 - val_loss: 0.0134 - 2s/epoch - 14ms/step\n",
      "Epoch 23/50\n",
      "122/122 - 2s - loss: 0.0145 - val_loss: 0.0133 - 2s/epoch - 13ms/step\n",
      "Epoch 24/50\n",
      "122/122 - 2s - loss: 0.0145 - val_loss: 0.0134 - 2s/epoch - 15ms/step\n",
      "Epoch 25/50\n",
      "122/122 - 1s - loss: 0.0145 - val_loss: 0.0134 - 1s/epoch - 12ms/step\n",
      "Epoch 26/50\n",
      "122/122 - 2s - loss: 0.0145 - val_loss: 0.0134 - 2s/epoch - 14ms/step\n",
      "Epoch 27/50\n",
      "122/122 - 2s - loss: 0.0145 - val_loss: 0.0134 - 2s/epoch - 13ms/step\n",
      "Epoch 28/50\n",
      "122/122 - 2s - loss: 0.0145 - val_loss: 0.0136 - 2s/epoch - 14ms/step\n",
      "Epoch 29/50\n",
      "122/122 - 2s - loss: 0.0145 - val_loss: 0.0135 - 2s/epoch - 13ms/step\n",
      "Epoch 30/50\n",
      "122/122 - 2s - loss: 0.0144 - val_loss: 0.0135 - 2s/epoch - 13ms/step\n",
      "Epoch 31/50\n",
      "122/122 - 2s - loss: 0.0144 - val_loss: 0.0134 - 2s/epoch - 14ms/step\n",
      "Epoch 32/50\n",
      "122/122 - 2s - loss: 0.0145 - val_loss: 0.0134 - 2s/epoch - 13ms/step\n",
      "Epoch 33/50\n",
      "122/122 - 2s - loss: 0.0144 - val_loss: 0.0134 - 2s/epoch - 14ms/step\n",
      "Epoch 34/50\n",
      "122/122 - 2s - loss: 0.0144 - val_loss: 0.0136 - 2s/epoch - 12ms/step\n",
      "Epoch 35/50\n",
      "122/122 - 2s - loss: 0.0143 - val_loss: 0.0138 - 2s/epoch - 15ms/step\n",
      "Epoch 36/50\n",
      "122/122 - 2s - loss: 0.0144 - val_loss: 0.0137 - 2s/epoch - 13ms/step\n",
      "Epoch 37/50\n",
      "122/122 - 2s - loss: 0.0143 - val_loss: 0.0136 - 2s/epoch - 14ms/step\n",
      "Epoch 38/50\n",
      "122/122 - 2s - loss: 0.0143 - val_loss: 0.0136 - 2s/epoch - 14ms/step\n",
      "Epoch 39/50\n",
      "122/122 - 2s - loss: 0.0143 - val_loss: 0.0138 - 2s/epoch - 14ms/step\n",
      "Epoch 40/50\n",
      "122/122 - 2s - loss: 0.0143 - val_loss: 0.0137 - 2s/epoch - 15ms/step\n",
      "Epoch 41/50\n",
      "122/122 - 2s - loss: 0.0143 - val_loss: 0.0136 - 2s/epoch - 13ms/step\n",
      "Epoch 42/50\n",
      "122/122 - 2s - loss: 0.0144 - val_loss: 0.0136 - 2s/epoch - 14ms/step\n",
      "Epoch 43/50\n",
      "122/122 - 2s - loss: 0.0143 - val_loss: 0.0135 - 2s/epoch - 15ms/step\n",
      "Epoch 44/50\n",
      "122/122 - 2s - loss: 0.0144 - val_loss: 0.0135 - 2s/epoch - 15ms/step\n",
      "Epoch 45/50\n",
      "122/122 - 2s - loss: 0.0143 - val_loss: 0.0135 - 2s/epoch - 19ms/step\n",
      "Epoch 46/50\n",
      "122/122 - 2s - loss: 0.0143 - val_loss: 0.0136 - 2s/epoch - 20ms/step\n",
      "Epoch 47/50\n",
      "122/122 - 3s - loss: 0.0143 - val_loss: 0.0136 - 3s/epoch - 24ms/step\n",
      "Epoch 48/50\n",
      "122/122 - 3s - loss: 0.0143 - val_loss: 0.0135 - 3s/epoch - 23ms/step\n",
      "Epoch 49/50\n",
      "122/122 - 2s - loss: 0.0143 - val_loss: 0.0135 - 2s/epoch - 17ms/step\n",
      "Epoch 50/50\n",
      "122/122 - 1s - loss: 0.0144 - val_loss: 0.0135 - 1s/epoch - 12ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test RMSE: 26.470\n"
     ]
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from numpy import concatenate\n",
    "from matplotlib import pyplot\n",
    "from pandas import read_csv\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    " \n",
    "# convert series to supervised learning\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg\n",
    " \n",
    "# load dataset\n",
    "dataset = read_csv('pollution.csv', header=0, index_col=0)\n",
    "values = dataset.values\n",
    "# integer encode direction\n",
    "encoder = LabelEncoder()\n",
    "values[:,4] = encoder.fit_transform(values[:,4])\n",
    "# ensure all data is float\n",
    "values = values.astype('float32')\n",
    "# normalize features\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled = scaler.fit_transform(values)\n",
    "# frame as supervised learning\n",
    "reframed = series_to_supervised(scaled, 1, 1)\n",
    "# drop columns we don't want to predict\n",
    "reframed.drop(reframed.columns[[9,10,11,12,13,14,15]], axis=1, inplace=True)\n",
    "print(reframed.head())\n",
    " \n",
    "# split into train and test sets\n",
    "values = reframed.values\n",
    "n_train_hours = 365 * 24\n",
    "train = values[:n_train_hours, :]\n",
    "test = values[n_train_hours:, :]\n",
    "# split into input and outputs\n",
    "train_X, train_y = train[:, :-1], train[:, -1]\n",
    "test_X, test_y = test[:, :-1], test[:, -1]\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "train_X = train_X.reshape((train_X.shape[0], 1, train_X.shape[1]))\n",
    "test_X = test_X.reshape((test_X.shape[0], 1, test_X.shape[1]))\n",
    "print(train_X.shape, train_y.shape, test_X.shape, test_y.shape)\n",
    " \n",
    "# design network\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_X.shape[1], train_X.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit network\n",
    "history = model.fit(train_X, train_y, epochs=50, batch_size=72, validation_data=(test_X, test_y), verbose=2, shuffle=False)\n",
    "# plot history\n",
    "pyplot.plot(history.history['loss'], label='train')\n",
    "pyplot.plot(history.history['val_loss'], label='test')\n",
    "pyplot.legend()\n",
    "pyplot.show()\n",
    " \n",
    "# make a prediction\n",
    "yhat = model.predict(test_X)\n",
    "test_X = test_X.reshape((test_X.shape[0], test_X.shape[2]))\n",
    "# invert scaling for forecast\n",
    "inv_yhat = concatenate((yhat, test_X[:, 1:]), axis=1)\n",
    "inv_yhat = scaler.inverse_transform(inv_yhat)\n",
    "inv_yhat = inv_yhat[:,0]\n",
    "# invert scaling for actual\n",
    "test_y = test_y.reshape((len(test_y), 1))\n",
    "inv_y = concatenate((test_y, test_X[:, 1:]), axis=1)\n",
    "inv_y = scaler.inverse_transform(inv_y)\n",
    "inv_y = inv_y[:,0]\n",
    "# calculate RMSE\n",
    "rmse = sqrt(mean_squared_error(inv_y, inv_yhat))\n",
    "print('Test RMSE: %.3f' % rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5179d32cf6ec497baf3f8a3ef987cc77c5d2dc691fdde20a56316522f61a7323"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
